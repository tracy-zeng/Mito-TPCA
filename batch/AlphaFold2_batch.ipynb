{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AlphaFold2_batch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tracy-zeng/Mito-TPCA/blob/main/batch/AlphaFold2_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "#ColabFold v1.5.5: AlphaFold2 w/ MMseqs2 BATCH\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"256\" align=\"right\" style=\"height:256px\">\n",
        "\n",
        "Easy to use AlphaFold2 protein structure [(Jumper et al. 2021)](https://www.nature.com/articles/s41586-021-03819-2) and complex [(Evans et al. 2021)](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1) prediction using multiple sequence alignments generated through MMseqs2. For details, refer to our manuscript:\n",
        "\n",
        "[Mirdita M, Schütze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1)\n",
        "\n",
        "**Usage**\n",
        "\n",
        "`input_dir` directory with only fasta files or MSAs stored in Google Drive. MSAs need to be A3M formatted and have an `.a3m` extention. For MSAs MMseqs2 will not be called.\n",
        "\n",
        "`result_dir` results will be written to the result directory in Google Drive\n",
        "\n",
        "Old versions: [v1.4](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.4.0/batch/AlphaFold2_batch.ipynb), [v1.5.1](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.1/batch/AlphaFold2_batch.ipynb), [v1.5.2](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.2/batch/AlphaFold2_batch.ipynb), [v1.5.3-patch](https://colab.research.google.com/github/sokrypton/ColabFold/blob/56c72044c7d51a311ca99b953a71e552fdc042e1/batch/AlphaFold2_batch.ipynb)\n",
        "\n",
        "<strong>For more details, see <a href=\"#Instructions\">bottom</a> of the notebook and checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold). </strong>\n",
        "\n",
        "-----------\n",
        "\n",
        "### News\n",
        "- <b><font color='green'>2023/07/31: The ColabFold MSA server is back to normal. It was using older DB (UniRef30 2202/PDB70 220313) from 27th ~8:30 AM CEST to 31st ~11:10 AM CEST.</font></b>\n",
        "- <b><font color='green'>2023/06/12: New databases! UniRef30 updated to 2023_02 and PDB to 230517. We now use PDB100 instead of PDB70 (see notes in the [main](https://colabfold.com) notebook).</font></b>\n",
        "- <b><font color='green'>2023/06/12: We introduced a new default pairing strategy: Previously, for multimer predictions with more than 2 chains, we only pair if all sequences taxonomically match (\"complete\" pairing). The new default \"greedy\" strategy pairs any taxonomically matching subsets.</font></b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwvIWN3HDyUJ",
        "cellView": "form"
      },
      "source": [
        "#@title Mount google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "from sys import version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\""
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = \"/content/input_fasta\"\n",
        "shutil.rmtree(input_dir)  # 删除整个文件夹\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "\n",
        "result_dir = '/content/result'\n",
        "shutil.rmtree(result_dir)  # 删除整个文件夹\n",
        "os.makedirs(result_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "oKKNMVHPW2Vv"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# 上传本地 fasta 文件（可以一次上传多个）\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 创建输入文件夹\n",
        "input_dir = '/content/input_fasta'\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "\n",
        "# 保存上传的文件到 input_dir\n",
        "for fname in uploaded.keys():\n",
        "    with open(os.path.join(input_dir, fname), 'wb') as f:\n",
        "        f.write(uploaded[fname])\n",
        "\n",
        "print(f\"已上传文件: {list(uploaded.keys())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "id": "PO2NK3RtVQIH",
        "outputId": "7e569dd7-a927-43fe-84dc-0d05f04cc72f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6002175c-b4e3-4f52-9831-06421abc39b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6002175c-b4e3-4f52-9831-06421abc39b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.fasta to test (10).fasta\n",
            "已上传文件: ['test (10).fasta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for f in os.listdir(input_dir):\n",
        "    new_name = re.sub(r\"\\s*\\(\\d+\\)\", \"\", f)  # 去掉括号和数字\n",
        "    old_path = os.path.join(input_dir, f)\n",
        "    new_path = os.path.join(input_dir, new_name)\n",
        "    if old_path != new_path:\n",
        "        os.rename(old_path, new_path)\n",
        "        print(f\"✅ Renamed '{f}' -> '{new_name}'\")"
      ],
      "metadata": {
        "id": "1MheNXxLgOU6",
        "outputId": "8f525bb0-e16a-4d9f-dba8-0f87055e2bc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Renamed 'test (10).fasta' -> 'test.fasta'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(input_dir))"
      ],
      "metadata": {
        "id": "zr2gHC48fzij",
        "outputId": "74f1b3e6-1402-47ea-ec1e-c3cca3b81a0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test.fasta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 自动拆分多序列 fasta\n",
        "from pathlib import Path\n",
        "\n",
        "fasta_file = list(Path(input_dir).glob(\"*.fasta\"))[0]\n",
        "out_dir = Path(input_dir)\n",
        "with open(fasta_file) as f:\n",
        "    content = f.read().split(\">\")[1:]  # 按 > 分割\n",
        "\n",
        "for block in content:\n",
        "    lines = block.strip().split(\"\\n\")\n",
        "    header = lines[0]\n",
        "    seq = \"\".join(lines[1:])\n",
        "    # 提取 Uniprot ID，例如 sp|A0AV02|...\n",
        "    uid = header.split(\"|\")[1]\n",
        "    out_path = out_dir / f\"{uid}.fasta\"\n",
        "    with open(out_path, \"w\") as out:\n",
        "        out.write(f\">{header}\\n{seq}\\n\")\n",
        "    print(f\"✅ Wrote {out_path}\")\n",
        "\n",
        "# 删除原始的大 fasta，避免重复\n",
        "Path(fasta_file).unlink()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODy8CyozXCpf",
        "outputId": "0e182415-fc6d-4247-d815-d109e69bf13e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote /content/input_fasta/A0A087X1C5.fasta\n",
            "✅ Wrote /content/input_fasta/A0A0B4J2F0.fasta\n",
            "✅ Wrote /content/input_fasta/A0A0C5B5G6.fasta\n",
            "✅ Wrote /content/input_fasta/A0A0K2S4Q6.fasta\n",
            "✅ Wrote /content/input_fasta/A0A0U1RRE5.fasta\n",
            "✅ Wrote /content/input_fasta/A0A1B0GTW7.fasta\n",
            "✅ Wrote /content/input_fasta/A0AV02.fasta\n",
            "✅ Wrote /content/input_fasta/A0AV96.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOblAo-xetgx",
        "cellView": "form"
      },
      "source": [
        "#@title Input protein sequence, then hit `Runtime` -> `Run all`\n",
        "\n",
        "input_dir = '/content/input_fasta' #@param {type:\"string\"}\n",
        "result_dir = '/content/result' #@param {type:\"string\"}\n",
        "os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "# number of models to use\n",
        "#@markdown ---\n",
        "#@markdown ### Advanced settings\n",
        "msa_mode = \"single_sequence\" #@param [\"MMseqs2 (UniRef+Environmental)\", \"MMseqs2 (UniRef only)\",\"single_sequence\",\"custom\"]\n",
        "num_models = 5 #@param [1,2,3,4,5] {type:\"raw\"}\n",
        "num_recycles = 3 #@param [1,3,6,12,24,48] {type:\"raw\"}\n",
        "stop_at_score = 100 #@param {type:\"string\"}\n",
        "#@markdown - early stop computing models once score > threshold (avg. plddt for \"structures\" and ptmscore for \"complexes\")\n",
        "use_custom_msa = False\n",
        "num_relax = 0 #@param [0, 1, 5] {type:\"raw\"}\n",
        "use_amber = num_relax > 0\n",
        "relax_max_iterations = 200 #@param [0,200,2000] {type:\"raw\"}\n",
        "use_templates = False #@param {type:\"boolean\"}\n",
        "do_not_overwrite_results = True #@param {type:\"boolean\"}\n",
        "zip_results = False #@param {type:\"boolean\"}\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install appdirs\n",
        "!pip install pdbfixer openmm"
      ],
      "metadata": {
        "id": "b9oxPDvRmBuM",
        "outputId": "e382531b-e97b-4bd5-f2e6-fdce401319e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting appdirs\n",
            "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: appdirs\n",
            "Successfully installed appdirs-1.4.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "appdirs"
                ]
              },
              "id": "8957df0efeb8443fbd6229b395e6b916"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdbfixer in /usr/local/lib/python3.12/site-packages (1.11.0)\n",
            "Requirement already satisfied: openmm in /usr/local/lib/python3.12/site-packages (8.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from pdbfixer) (2.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iccGdbe_Pmt9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "a7de85e3-448b-4192-97fe-dec5819d1b72"
      },
      "source": [
        "#@title Install dependencies\n",
        "%%bash -s $use_amber $use_templates $python_version\n",
        "\n",
        "set -e\n",
        "\n",
        "USE_AMBER=$1\n",
        "USE_TEMPLATES=$2\n",
        "PYTHON_VERSION=$3\n",
        "\n",
        "if [ ! -f COLABFOLD_READY ]; then\n",
        "  # install dependencies\n",
        "  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\n",
        "  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\"\n",
        "  if [ -n \"${TPU_NAME}\" ]; then\n",
        "    pip install -q --no-warn-conflicts -U dm-haiku==0.0.10 jax==0.3.25\n",
        "  fi\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\n",
        "  # hack to fix TF crash\n",
        "  rm -f /usr/local/lib/python3.*/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so\n",
        "  touch COLABFOLD_READY\n",
        "fi\n",
        "\n",
        "# Download params (~1min)\n",
        "python -m colabfold.download\n",
        "\n",
        "# setup conda\n",
        "if [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
        "  if [ ! -f CONDA_READY ]; then\n",
        "    wget -qnc https://github.com/conda-forge/miniforge/releases/download/25.3.1-0/Miniforge3-25.3.1-0-Linux-x86_64.sh\n",
        "    bash Miniforge3-25.3.1-0-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "    rm Miniforge3-25.3.1-0-Linux-x86_64.sh\n",
        "    conda config --set auto_update_conda false\n",
        "    touch CONDA_READY\n",
        "  fi\n",
        "fi\n",
        "# setup template search\n",
        "if [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\n",
        "  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=\"${PYTHON_VERSION}\" 2>&1 1>/dev/null\n",
        "  touch HH_READY\n",
        "fi\n",
        "# setup openmm for amber refinement\n",
        "if [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\n",
        "  conda install -y -q -c conda-forge openmm=8.2.0 python=\"${PYTHON_VERSION}\" pdbfixer 2>&1 1>/dev/null\n",
        "  touch AMBER_READY\n",
        "fi"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/colabfold/download.py\", line 6, in <module>\n",
            "    import appdirs\n",
            "ModuleNotFoundError: No module named 'appdirs'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'\\nset -e\\n\\nUSE_AMBER=$1\\nUSE_TEMPLATES=$2\\nPYTHON_VERSION=$3\\n\\nif [ ! -f COLABFOLD_READY ]; then\\n  # install dependencies\\n  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\\n  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\"\\n  if [ -n \"${TPU_NAME}\" ]; then\\n    pip install -q --no-warn-conflicts -U dm-haiku==0.0.10 jax==0.3.25\\n  fi\\n  ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\\n  ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\\n  # hack to fix TF crash\\n  rm -f /usr/local/lib/python3.*/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so\\n  touch COLABFOLD_READY\\nfi\\n\\n# Download params (~1min)\\npython -m colabfold.download\\n\\n# setup conda\\nif [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\\n  if [ ! -f CONDA_READY ]; then\\n    wget -qnc https://github.com/conda-forge/miniforge/releases/download/25.3.1-0/Miniforge3-25.3.1-0-Linux-x86_64.sh\\n    bash Miniforge3-25.3.1-0-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\\n    rm Miniforge3-25.3.1-0-Linux-x86_64.sh\\n    conda config --set auto_update_conda false\\n    touch CONDA_READY\\n  fi\\nfi\\n# setup template search\\nif [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\\n  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=\"${PYTHON_VERSION}\" 2>&1 1>/dev/null\\n  touch HH_READY\\nfi\\n# setup openmm for amber refinement\\nif [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\\n  conda install -y -q -c conda-forge openmm=8.2.0 python=\"${PYTHON_VERSION}\" pdbfixer 2>&1 1>/dev/null\\n  touch AMBER_READY\\nfi\\n'' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1848081751.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-s $use_amber $use_templates $python_version'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nset -e\\n\\nUSE_AMBER=$1\\nUSE_TEMPLATES=$2\\nPYTHON_VERSION=$3\\n\\nif [ ! -f COLABFOLD_READY ]; then\\n  # install dependencies\\n  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\\n  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\"\\n  if [ -n \"${TPU_NAME}\" ]; then\\n    pip install -q --no-warn-conflicts -U dm-haiku==0.0.10 jax==0.3.25\\n  fi\\n  ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\\n  ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\\n  # hack to fix TF crash\\n  rm -f /usr/local/lib/python3.*/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so\\n  touch COLABFOLD_READY\\nfi\\n\\n# Download params (~1min)\\npython -m colabfold.download\\n\\n# setup conda\\nif [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\\n  if [ ! -f CONDA_READY ]; then\\n    wget -qnc https://github.com/conda-forge/miniforge/releases/download/25.3.1-0/Miniforge3-25.3.1-0-Linux-x86_64.sh\\n    bash Miniforge3-25.3.1-0-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\\n    rm Miniforge3-25.3.1-0-Linux-x86_64.sh\\n    conda config --set auto_update_conda false\\n    touch CONDA_READY\\n  fi\\nfi\\n# setup temp...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\nset -e\\n\\nUSE_AMBER=$1\\nUSE_TEMPLATES=$2\\nPYTHON_VERSION=$3\\n\\nif [ ! -f COLABFOLD_READY ]; then\\n  # install dependencies\\n  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\\n  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\"\\n  if [ -n \"${TPU_NAME}\" ]; then\\n    pip install -q --no-warn-conflicts -U dm-haiku==0.0.10 jax==0.3.25\\n  fi\\n  ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\\n  ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\\n  # hack to fix TF crash\\n  rm -f /usr/local/lib/python3.*/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so\\n  touch COLABFOLD_READY\\nfi\\n\\n# Download params (~1min)\\npython -m colabfold.download\\n\\n# setup conda\\nif [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\\n  if [ ! -f CONDA_READY ]; then\\n    wget -qnc https://github.com/conda-forge/miniforge/releases/download/25.3.1-0/Miniforge3-25.3.1-0-Linux-x86_64.sh\\n    bash Miniforge3-25.3.1-0-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\\n    rm Miniforge3-25.3.1-0-Linux-x86_64.sh\\n    conda config --set auto_update_conda false\\n    touch CONDA_READY\\n  fi\\nfi\\n# setup template search\\nif [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\\n  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=\"${PYTHON_VERSION}\"..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== Run Prediction ==================\n",
        "import sys, os, re, shutil\n",
        "from pathlib import Path\n",
        "from colabfold.batch import get_queries, run\n",
        "from colabfold.download import default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "\n",
        "!pip install pdbfixer\n",
        "!pip install openmm\n",
        "\n",
        "# 确保pdbfixer可以导入\n",
        "if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "setup_logging(Path(result_dir).joinpath(\"log.txt\"))\n",
        "\n",
        "# 获取输入序列\n",
        "queries, is_complex = get_queries(input_dir)\n",
        "\n",
        "# 运行预测，只取 top1\n",
        "run(\n",
        "    queries=queries,\n",
        "    result_dir=result_dir,\n",
        "    use_templates=use_templates,\n",
        "    num_relax=num_relax,\n",
        "    relax_max_iterations=relax_max_iterations,\n",
        "    msa_mode=msa_mode,\n",
        "    model_type=\"auto\",\n",
        "    num_models=1,                 # 🔑 只跑一个模型\n",
        "    num_recycles=num_recycles,\n",
        "    model_order=[1],\n",
        "    is_complex=is_complex,\n",
        "    data_dir=default_data_dir,\n",
        "    keep_existing_results=False,\n",
        "    rank_by=\"auto\",\n",
        "    pair_mode=\"unpaired\",\n",
        "    stop_at_score=stop_at_score,\n",
        "    zip_results=False,\n",
        "    user_agent=\"colabfold/google-colab-batch\",\n",
        ")\n",
        "\n",
        "# ================== Rename Results ==================\n",
        "fasta_file = list(Path(input_dir).glob(\"*.fasta\"))[0]\n",
        "with open(fasta_file, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# 提取序列名和 Uniprot ID\n",
        "seq_ids = [re.search(r\"sp\\|([^|]+)\\|\", line).group(1)\n",
        "           for line in lines if line.startswith(\">\")]\n",
        "\n",
        "# 给每个序列结果改名\n",
        "for sid in seq_ids:\n",
        "    seq_dir = Path(result_dir) / sid\n",
        "    if seq_dir.exists():\n",
        "        src_pdb = seq_dir / \"ranked_0.pdb\"\n",
        "        dst_pdb = Path(result_dir) / f\"{sid}.pdb\"\n",
        "        if src_pdb.exists():\n",
        "            shutil.copy(src_pdb, dst_pdb)\n",
        "            print(f\"✅ Saved {dst_pdb}\")\n",
        "        else:\n",
        "            print(f\"⚠️ No ranked_0.pdb found for {sid}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "5-RWjQ5aVhGY",
        "outputId": "8ea063e4-5598-4dda-d01f-9b208ea62585"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdbfixer in /usr/local/lib/python3.12/site-packages (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from pdbfixer) (2.3.2)\n",
            "Requirement already satisfied: openmm>=8.2 in /usr/local/lib/python3.12/site-packages (from pdbfixer) (8.2.0)\n",
            "Requirement already satisfied: openmm in /usr/local/lib/python3.12/site-packages (8.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from openmm) (2.3.2)\n",
            "2025-09-09 08:24:50,493 Running on GPU\n",
            "2025-09-09 08:24:50,496 Found 3 citations for tools or databases\n",
            "2025-09-09 08:24:50,496 Query 1/8: A0A0C5B5G6 (length 16)\n",
            "2025-09-09 08:24:58,197 Padding length to 26\n",
            "2025-09-09 08:25:15,440 alphafold2_ptm_model_1_seed_000 recycle=0 pLDDT=64.8 pTM=0.0259\n",
            "2025-09-09 08:25:32,903 alphafold2_ptm_model_1_seed_000 recycle=1 pLDDT=65.5 pTM=0.0262 tol=1.06\n",
            "2025-09-09 08:25:33,088 alphafold2_ptm_model_1_seed_000 recycle=2 pLDDT=63.8 pTM=0.0265 tol=0.924\n",
            "2025-09-09 08:25:33,267 alphafold2_ptm_model_1_seed_000 recycle=3 pLDDT=65.9 pTM=0.027 tol=1.03\n",
            "2025-09-09 08:25:33,267 alphafold2_ptm_model_1_seed_000 took 35.1s (3 recycles)\n",
            "2025-09-09 08:25:33,270 reranking models by 'plddt' metric\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pdbfixer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1748619962.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 运行预测，只取 top1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m run(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mresult_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/colabfold/batch.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(queries, result_dir, num_models, is_complex, num_recycles, recycle_early_stop_tolerance, model_order, initial_guess, num_ensemble, model_type, msa_mode, use_templates, custom_template_path, num_relax, relax_max_iterations, relax_tolerance, relax_stiffness, relax_max_outer_iterations, keep_existing_results, rank_by, pair_mode, pairing_strategy, data_dir, host_url, user_agent, random_seed, num_seeds, recompile_padding, zip_results, prediction_callback, save_single_representations, save_pair_representations, jobname_prefix, save_all, save_recycles, use_dropout, use_gpu_relax, stop_at_score, dpi, max_seq, max_extra_seq, pdb_hit_file, local_pdb_path, use_cluster_profile, feature_dict_callback, calc_extra_ptm, use_probs_extra, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m                     \u001b[0mfirst_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m                 results = predict_structure(\n\u001b[0m\u001b[1;32m   1432\u001b[0m                     \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjobname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m                     \u001b[0mresult_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/colabfold/batch.py\u001b[0m in \u001b[0;36mpredict_structure\u001b[0;34m(prefix, result_dir, feature_dict, is_complex, use_templates, sequences_lengths, pad_len, model_type, model_runner_and_params, initial_guess, num_relax, relax_max_iterations, relax_tolerance, relax_stiffness, relax_max_outer_iterations, rank_by, random_seed, num_seeds, stop_at_score, prediction_callback, use_gpu_relax, save_all, save_single_representations, save_pair_representations, save_recycles, calc_extra_ptm, use_probs_extra)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_relax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             pdb_lines = relax_me(\n\u001b[0m\u001b[1;32m    536\u001b[0m                 \u001b[0mpdb_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munrelaxed_pdb_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelax_max_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/colabfold/relax.py\u001b[0m in \u001b[0;36mrelax_me\u001b[0;34m(pdb_filename, pdb_lines, pdb_obj, use_gpu, max_iterations, tolerance, stiffness, max_outer_iterations)\u001b[0m\n\u001b[1;32m     12\u001b[0m ):\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0malphafold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprotein\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0malphafold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrelax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpdb_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/alphafold/relax/relax.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malphafold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprotein\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malphafold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mamber_minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malphafold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/alphafold/relax/amber_minimize.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malphafold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresidue_constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malphafold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfolding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malphafold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malphafold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mml_collections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/alphafold/relax/cleanup.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpdbfixer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenmm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdbfixer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(result_dir):\n",
        "    for f in files:\n",
        "        if not f.endswith(\".pdb\"):  # 不是 pdb 的文件\n",
        "            file_path = os.path.join(root, f)\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "            except Exception as e:\n",
        "              pass"
      ],
      "metadata": {
        "id": "CzdVFVaCd-px"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# 压缩整个 result 文件夹\n",
        "shutil.make_archive(\"results\", \"zip\", result_dir)\n",
        "\n",
        "# 下载到本地\n",
        "from google.colab import files\n",
        "files.download(\"results.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Wv0tTru8Yqk5",
        "outputId": "f6c95c0f-bed8-4139-e60c-1757dec4fb56"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2812ffbf-0d88-4400-a87f-bf668952a5f0\", \"results.zip\", 528199)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import glob\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "zip_filename = \"pdb_results.zip\"\n",
        "\n",
        "# 递归查找所有子文件夹里的 pdb\n",
        "pdb_files = glob.glob(f\"{result_dir}/**/*.pdb\", recursive=True)\n",
        "print(f\"找到 {len(pdb_files)} 个 PDB 文件\")\n",
        "\n",
        "# 创建 zip，只保留文件名，不带路径\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    for pdb in pdb_files:\n",
        "        zipf.write(pdb, arcname=os.path.basename(pdb))\n",
        "\n",
        "# 下载 zip\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "id": "ePpBTVTFeoni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUYApPElB30u"
      },
      "source": [
        "#@title Run Prediction\n",
        "\n",
        "import sys\n",
        "\n",
        "from colabfold.batch import get_queries, run\n",
        "from colabfold.download import default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "from pathlib import Path\n",
        "\n",
        "# For some reason we need that to get pdbfixer to import\n",
        "if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "setup_logging(Path(result_dir).joinpath(\"log.txt\"))\n",
        "\n",
        "queries, is_complex = get_queries(input_dir)\n",
        "run(\n",
        "    queries=queries,\n",
        "    result_dir=result_dir,\n",
        "    use_templates=use_templates,\n",
        "    num_relax=num_relax,\n",
        "    relax_max_iterations=relax_max_iterations,\n",
        "    msa_mode=msa_mode,\n",
        "    model_type=\"auto\",\n",
        "    num_models=num_models,\n",
        "    num_recycles=num_recycles,\n",
        "    model_order=[1, 2, 3, 4, 5],\n",
        "    is_complex=is_complex,\n",
        "    data_dir=default_data_dir,\n",
        "    keep_existing_results=do_not_overwrite_results,\n",
        "    rank_by=\"auto\",\n",
        "    pair_mode=\"unpaired+paired\",\n",
        "    stop_at_score=stop_at_score,\n",
        "    zip_results=zip_results,\n",
        "    user_agent=\"colabfold/google-colab-batch\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUBLzB3C6WN"
      },
      "source": [
        "# Instructions <a name=\"Instructions\"></a>\n",
        "**Quick start**\n",
        "1. Upload your single fasta files to a folder in your Google Drive\n",
        "2. Define path to the fold containing the fasta files (`input_dir`) define an outdir (`output_dir`)\n",
        "3. Press \"Runtime\" -> \"Run all\".\n",
        "\n",
        "**Result zip file contents**\n",
        "\n",
        "At the end of the job a all results `jobname.result.zip` will be uploaded to your (`output_dir`) Google Drive. Each zip contains one protein.\n",
        "\n",
        "1. PDB formatted structures sorted by avg. pIDDT. (unrelaxed and relaxed if `use_amber` is enabled).\n",
        "2. Plots of the model quality.\n",
        "3. Plots of the MSA coverage.\n",
        "4. Parameter log file.\n",
        "5. A3M formatted input MSA.\n",
        "6. BibTeX file with citations for all used tools and databases.\n",
        "\n",
        "\n",
        "**Troubleshooting**\n",
        "* Check that the runtime type is set to GPU at \"Runtime\" -> \"Change runtime type\".\n",
        "* Try to restart the session \"Runtime\" -> \"Factory reset runtime\".\n",
        "* Check your input sequence.\n",
        "\n",
        "**Known issues**\n",
        "* Google Colab assigns different types of GPUs with varying amount of memory. Some might not have enough memory to predict the structure for a long sequence.\n",
        "* Google Colab assigns different types of GPUs with varying amount of memory. Some might not have enough memory to predict the structure for a long sequence.\n",
        "* Your browser can block the pop-up for downloading the result file. You can choose the `save_to_google_drive` option to upload to Google Drive instead or manually download the result file: Click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "\n",
        "**Limitations**\n",
        "* Computing resources: Our MMseqs2 API can handle ~20-50k requests per day.\n",
        "* MSAs: MMseqs2 is very precise and sensitive but might find less hits compared to HHblits/HMMer searched against BFD or Mgnify.\n",
        "* We recommend to additionally use the full [AlphaFold2 pipeline](https://github.com/deepmind/alphafold).\n",
        "\n",
        "**Description of the plots**\n",
        "*   **Number of sequences per position** - We want to see at least 30 sequences per position, for best performance, ideally 100 sequences.\n",
        "*   **Predicted lDDT per position** - model confidence (out of 100) at each position. The higher the better.\n",
        "*   **Predicted Alignment Error** - For homooligomers, this could be a useful metric to assess how confident the model is about the interface. The lower the better.\n",
        "\n",
        "**Bugs**\n",
        "- If you encounter any bugs, please report the issue to https://github.com/sokrypton/ColabFold/issues\n",
        "\n",
        "**License**\n",
        "\n",
        "The source code of ColabFold is licensed under [MIT](https://raw.githubusercontent.com/sokrypton/ColabFold/main/LICENSE). Additionally, this notebook uses AlphaFold2 source code and its parameters licensed under [Apache 2.0](https://raw.githubusercontent.com/deepmind/alphafold/main/LICENSE) and  [CC BY 4.0](https://creativecommons.org/licenses/by-sa/4.0/) respectively. Read more about the AlphaFold license [here](https://github.com/deepmind/alphafold).\n",
        "\n",
        "**Acknowledgments**\n",
        "- We thank the AlphaFold team for developing an excellent model and open sourcing the software.\n",
        "\n",
        "- Do-Yoon Kim for creating the ColabFold logo.\n",
        "\n",
        "- A colab by Sergey Ovchinnikov ([@sokrypton](https://twitter.com/sokrypton)), Milot Mirdita ([@milot_mirdita](https://twitter.com/milot_mirdita)) and Martin Steinegger ([@thesteinegger](https://twitter.com/thesteinegger)).\n"
      ]
    }
  ]
}